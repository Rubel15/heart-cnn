{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "import pyfits\n",
    "import dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import sklearn, sklearn.preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-80-b386ced26a42>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-80-b386ced26a42>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    calmPadded.append(np.lib.pad(calmTmp[i],                                      ((aC[1]/2, aC[1]/2 + aC[1]%2), (aC[2]/2, aC[2]/2 + aC[2]%2))                                     'linear_ramp'))\u001b[0m\n\u001b[0m                                                                                                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def importHeartData(calmFile, stressFile):\n",
    "    \"\"\"\n",
    "    Import heart data and extract the pixel array.\n",
    "    Concatenate and return stress file and calm file.\n",
    "    \"\"\"\n",
    "    calmTmp = dicom.read_file(calmFile).pixel_array\n",
    "    stressTmp = dicom.read_file(stressFile).pixel_array\n",
    "    \n",
    "    calmTmp = cropHeart(calmTmp)\n",
    "    stressTmp = cropHeart(stressTmp)\n",
    "    \n",
    "    calmPadded = []\n",
    "    stressPadded = []\n",
    "    \n",
    "    aC = [30-i for i in calmTmp.shape]\n",
    "    aS = [30-i for i in stressTmp.shape]\n",
    "    \n",
    "    for i in np.arange(calmTmp.shape[0]):\n",
    "        calmPadded.append(np.lib.pad(calmTmp[i], \\\n",
    "                                     ((aC[1]/2, aC[1]/2 + aC[1]%2), (aC[2]/2, aC[2]/2 + aC[2]%2))\\\n",
    "                                     'linear_ramp'))\n",
    "        stressPadded.append(np.lib.pad(stressTmp[i], \\\n",
    "                                       ((aS[1]/2, aS[1]/2 + aS[1]%2), (aS[2]/2, aS[2]/2 + aS[2]%2))\\\n",
    "                                       'linear_ramp'))\n",
    "    \n",
    "    \n",
    "    #catOut = np.concatenate([calmTmp, stressTmp])\n",
    "    #return calmTmp, stressTmp\n",
    "\n",
    "def importDir(parentDir):\n",
    "    \"\"\"\n",
    "    Scan though directories in parent directory; look for dirs labelled \n",
    "    STRESS* or REST* in the imediate subsirs and import any dcm files in them.\n",
    "    Return a dataFile of the concatenated stress and calm *.dcm files.\n",
    "    \"\"\"\n",
    "    tmplst = []\n",
    "    for dirs in os.listdir(parentDir):\n",
    "        cwdStress = glob.glob(parentDir+\"/\"+dirs+\"/STRESS*/*.dcm\")\n",
    "        cwdCalm = glob.glob(parentDir+\"/\"+dirs+\"/REST*/*.dcm\")\n",
    "        tmplst.append(importHeartData(cwdCalm[0], cwdStress[0]))\n",
    "    dataFile = np.array(tmplst)\n",
    "    return dataFile\n",
    "\n",
    "def cropHeart(inp):\n",
    "    \"\"\"\n",
    "    Crop the heart so that all the padding is done away with.\n",
    "    Output cropped heart.\n",
    "    \"\"\"\n",
    "    # argwhere will give you the coordinates of every non-zero point\n",
    "    true_points = np.argwhere(inp)\n",
    "    # take the smallest points and use them as the top left of your crop\n",
    "    top_left = true_points.min(axis=0)\n",
    "    # take the largest points and use them as the bottom right of your crop\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "    out = inp[top_left[0]:bottom_right[0]+1,  # plus 1 because slice isn't\n",
    "          top_left[1]:bottom_right[1]+1,   # inclusive\n",
    "          top_left[2]:bottom_right[2]+1]  \n",
    "    print(inp.shape, out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((33, 64, 64), (20, 16, 21))\n",
      "((35, 64, 64), (21, 17, 22))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pad() takes exactly 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-1c9dee942222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Do data import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnormDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/nlst\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mabDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/rlst\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mabDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-f06919b9a1e2>\u001b[0m in \u001b[0;36mimportDir\u001b[0;34m(parentDir)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcwdStress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/STRESS*/*.dcm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mcwdCalm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/REST*/*.dcm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtmplst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportHeartData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwdCalm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwdStress\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mdataFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmplst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-f06919b9a1e2>\u001b[0m in \u001b[0;36mimportHeartData\u001b[0;34m(calmFile, stressFile)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalmTmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcalmPadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalmTmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mstressPaddes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstressTmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pad() takes exactly 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "# Do data import\n",
    "normDir = \"./data/nlst\"\n",
    "normDat = importDir(normDir)\n",
    "abDir = \"./data/rlst\"\n",
    "abDat = importDir(abDir)\n",
    "inData = np.concatenate([normDat[:abDat.shape[0]], abDat]) # Normal and abnormal data same shape\n",
    "\n",
    "# Do labelling\n",
    "normLab = np.zeros(normDat.shape[0])[:abDat.shape[0]]\n",
    "abLab = np.ones(abDat.shape[0])\n",
    "labels = np.concatenate([normLab, abLab])\n",
    "    \n",
    "# Mutual shuffle\n",
    "shufData, shufLab = sklearn.utils.shuffle(inData, labels, random_state=1)\n",
    "shufData = np.reshape(shufData,(-1,40,64,64,1))\n",
    "shufLabOH = np.eye(2)[labels.astype(int)] # One hot encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m10.71379\u001b[0m\u001b[0m | time: 84.875s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 004 | loss: 10.71379 - acc: 0.5341 -- iter: 29/58\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.reset_default_graph()\n",
    "tflearn.initializations.normal()\n",
    "\n",
    "# Input layer:\n",
    "net = tflearn.layers.core.input_data(shape=[None, 58, 64, 64, 1])\n",
    "\n",
    "# First layer:\n",
    "net = tflearn.layers.conv.conv_3d(net, 8, [5,5,5],  activation=\"leaky_relu\")\n",
    "net = tflearn.layers.conv.max_pool_3d(net, 2, strides=2)\n",
    "\n",
    "# Second layer:\n",
    "net = tflearn.layers.conv.conv_3d(net, 16, [5,5,5], activation=\"leaky_relu\")\n",
    "net = tflearn.layers.conv.max_pool_3d(net, 2, strides=2)\n",
    "\n",
    "# Fully connected layer\n",
    "net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "\n",
    "# Dropout layer:\n",
    "net = tflearn.layers.core.dropout(net, keep_prob=0.5)\n",
    "\n",
    "# Output layer:\n",
    "net = tflearn.layers.core.fully_connected(net, 2, activation=\"softmax\")\n",
    "\n",
    "net = tflearn.layers.estimator.regression(net, optimizer='adam', learning_rate=0.0001, loss='categorical_crossentropy')\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(shufData, shufLabOH, batch_size=29, n_epoch=10, show_metric=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
