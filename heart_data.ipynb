{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "import pyfits\n",
    "import dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import sklearn, sklearn.preprocessing\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif calmTmp.shape[0] != 34:\\n            startInd = (34 - calmTmp.shape[0])/2\\n            zeroArr0[startInd:calmTmp.shape[0]+startInd,:calmTmp.shape[1],:calmTmp.shape[2]] = calmTmp\\n        if calmTmp.shape[1] != 34:\\n            startInd = (34 - calmTmp.shape[1])/2\\n            zeroArr0[:calmTmp.shape[0],startInd:calmTmp.shape[1]+startInd,:calmTmp.shape[2]] = calmTmp\\n        if calmTmp.shape[2] != 34:\\n            startInd = (34 - calmTmp.shape[2])/2\\n            zeroArr0[:calmTmp.shape[0],:calmTmp.shape[1],startInd:calmTmp.shape[2]+startInd] = calmTmp\\n\\n        if stressTmp.shape[0] != 34:\\n            startInd = (34 - stressTmp.shape[0])/2\\n            zeroArr1[startInd:stressTmp.shape[0]+startInd,:stressTmp.shape[1],:stressTmp.shape[2]] = stressTmp\\n        if stressTmp.shape[1] != 34:\\n            startInd = (34 - stressTmp.shape[1])/2\\n            zeroArr1[:stressTmp.shape[0],startInd:stressTmp.shape[1]+startInd,:stressTmp.shape[2]] = stressTmp\\n        if stressTmp.shape[2] != 34:\\n            startInd = (34 - stressTmp.shape[2])/2\\n            zeroArr1[:stressTmp.shape[0],:stressTmp.shape[1],startInd:stressTmp.shape[2]+startInd] = stressTmp\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use in importHeartData(x,y,z) to centre image\n",
    "\"\"\"\n",
    "if calmTmp.shape[0] != 34:\n",
    "            startInd = (34 - calmTmp.shape[0])/2\n",
    "            zeroArr0[startInd:calmTmp.shape[0]+startInd,:calmTmp.shape[1],:calmTmp.shape[2]] = calmTmp\n",
    "        if calmTmp.shape[1] != 34:\n",
    "            startInd = (34 - calmTmp.shape[1])/2\n",
    "            zeroArr0[:calmTmp.shape[0],startInd:calmTmp.shape[1]+startInd,:calmTmp.shape[2]] = calmTmp\n",
    "        if calmTmp.shape[2] != 34:\n",
    "            startInd = (34 - calmTmp.shape[2])/2\n",
    "            zeroArr0[:calmTmp.shape[0],:calmTmp.shape[1],startInd:calmTmp.shape[2]+startInd] = calmTmp\n",
    "\n",
    "        if stressTmp.shape[0] != 34:\n",
    "            startInd = (34 - stressTmp.shape[0])/2\n",
    "            zeroArr1[startInd:stressTmp.shape[0]+startInd,:stressTmp.shape[1],:stressTmp.shape[2]] = stressTmp\n",
    "        if stressTmp.shape[1] != 34:\n",
    "            startInd = (34 - stressTmp.shape[1])/2\n",
    "            zeroArr1[:stressTmp.shape[0],startInd:stressTmp.shape[1]+startInd,:stressTmp.shape[2]] = stressTmp\n",
    "        if stressTmp.shape[2] != 34:\n",
    "            startInd = (34 - stressTmp.shape[2])/2\n",
    "            zeroArr1[:stressTmp.shape[0],:stressTmp.shape[1],startInd:stressTmp.shape[2]+startInd] = stressTmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importHeartData(calmFile, stressFile, resize):\n",
    "    \"\"\"\n",
    "    Import heart data and extract the pixel array.\n",
    "    Concatenate and return stress file and calm file.\n",
    "    If resize == 1 resize zoom image to ~[34,34,34].\n",
    "    \"\"\"\n",
    "    calmTmp = dicom.read_file(calmFile).pixel_array\n",
    "    stressTmp = dicom.read_file(stressFile).pixel_array\n",
    "    \n",
    "    calmTmp = cropHeart(calmTmp)\n",
    "    stressTmp = cropHeart(stressTmp)\n",
    "\n",
    "    # Pad the 2d slices with zeros so that they are all the same size\n",
    "    zeroArr0 = np.zeros((34,34,34))\n",
    "    zeroArr1 = np.zeros((34,34,34))\n",
    "    \n",
    "    if resize == 1:      \n",
    "        # Resize the input data\n",
    "        calmRatio = 34.0/np.amax(calmTmp.shape)\n",
    "        stressRatio = 34.0/np.amax(stressTmp.shape)\n",
    "\n",
    "        calmTmp = scipy.ndimage.interpolation.zoom(calmTmp, (calmRatio))\n",
    "        stressTmp = scipy.ndimage.interpolation.zoom(stressTmp, (stressRatio))\n",
    "\n",
    "        # Put previous cell code here to centre image\n",
    "        zeroArr0[:calmTmp.shape[0],:calmTmp.shape[1],:calmTmp.shape[2]] = calmTmp\n",
    "        zeroArr1[:stressTmp.shape[0],:stressTmp.shape[1],:stressTmp.shape[2]] = stressTmp\n",
    "        \n",
    "        # Normalise the 2d slices\n",
    "        #zeroArr0 = sklearn.preprocessing.normalize(zeroArr0)\n",
    "        #zeroArr1 = sklearn.preprocessing.normalize(zeroArr1)\n",
    "        \n",
    "    else:\n",
    "        zeroArr0[:calmTmp.shape[0],:calmTmp.shape[1],:calmTmp.shape[2]] = calmTmp\n",
    "        zeroArr1[:stressTmp.shape[0],:stressTmp.shape[1],:stressTmp.shape[2]] = stressTmp\n",
    "\n",
    "    catOut = np.concatenate([zeroArr0, zeroArr1])\n",
    "    return catOut\n",
    "\n",
    "def importDir(parentDir):\n",
    "    \"\"\"\n",
    "    Scan though directories in parent directory; look for dirs labelled \n",
    "    STRESS* or REST* in the imediate subsirs and import any dcm files in them.\n",
    "    Return a dataFile of the concatenated stress and calm *.dcm files.\n",
    "    \"\"\"\n",
    "    tmplst = []\n",
    "    for dirs in os.listdir(parentDir):\n",
    "        cwdStress = glob.glob(parentDir+\"/\"+dirs+\"/STRESS*/*.dcm\")\n",
    "        cwdCalm = glob.glob(parentDir+\"/\"+dirs+\"/REST*/*.dcm\")\n",
    "        tmplst.append(importHeartData(cwdCalm[0], cwdStress[0],1))\n",
    "    dataFile = np.array(tmplst)\n",
    "    return dataFile\n",
    "\n",
    "def cropHeart(inp):\n",
    "    \"\"\"\n",
    "    Crop the heart so that all the padding is done away with.\n",
    "    Output cropped heart.\n",
    "    \"\"\"\n",
    "    # argwhere will give you the coordinates of every non-zero point\n",
    "    true_points = np.argwhere(inp)\n",
    "    # take the smallest points and use them as the top left of your crop\n",
    "    top_left = true_points.min(axis=0)\n",
    "    # take the largest points and use them as the bottom right of your crop\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "    out = inp[top_left[0]:bottom_right[0]+1,  # plus 1 because slice isn't\n",
    "          top_left[1]:bottom_right[1]+1,   # inclusive\n",
    "          top_left[2]:bottom_right[2]+1]  \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do data import\n",
    "normDir = \"./data/nlst\"\n",
    "normDat = importDir(normDir)\n",
    "abDir = \"./data/rlst\"\n",
    "abDat = importDir(abDir)\n",
    "inData = np.concatenate([normDat[:abDat.shape[0]], abDat]) # Normal and abnormal data same number of ppts\n",
    "\n",
    "# Do labelling\n",
    "normLab = np.zeros(normDat.shape[0])[:abDat.shape[0]]\n",
    "abLab = np.ones(abDat.shape[0])\n",
    "labels = np.concatenate([normLab, abLab])\n",
    "    \n",
    "# Mutual shuffle\n",
    "shufData, shufLab = sklearn.utils.shuffle(inData, labels, random_state=1)\n",
    "shufData = np.reshape(shufData,(-1,68,34,34,1))\n",
    "shufLabOH = np.eye(2)[labels.astype(int)] # One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 68, 34, 34, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f963a5afd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(shufData[5,16].reshape((34,34)))\n",
    "print(shufData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: V0IYUD\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 52\n",
      "Validation samples: 6\n",
      "--\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1ed84851555f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_verbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshufData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshufLabOH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                                                        show_metric)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                             \u001b[0;31m# Update training state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.pyc\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[0;32m--> 818\u001b[0;31m                                              feed_batch)\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;31m# Retrieve loss value from summary string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.reset_default_graph()\n",
    "tflearn.initializations.normal()\n",
    "\n",
    "# Input layer:\n",
    "net = tflearn.layers.core.input_data(shape=[None, 68, 34, 34, 1])\n",
    "\n",
    "# First layer:\n",
    "net = tflearn.layers.conv.conv_3d(net, 8, [5,5,5],  activation=\"leaky_relu\")\n",
    "net = tflearn.layers.conv.max_pool_3d(net, 2, strides=2)\n",
    "\n",
    "# Second layer:\n",
    "net = tflearn.layers.conv.conv_3d(net, 16, [5,5,5], activation=\"leaky_relu\")\n",
    "net = tflearn.layers.conv.max_pool_3d(net, 2, strides=2)\n",
    "\n",
    "# Fully connected layer\n",
    "net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "\n",
    "# Dropout layer:\n",
    "net = tflearn.layers.core.dropout(net, keep_prob=0.5)\n",
    "\n",
    "# Output layer:\n",
    "net = tflearn.layers.core.fully_connected(net, 2, activation=\"softmax\")\n",
    "\n",
    "net = tflearn.layers.estimator.regression(net, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy')\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(shufData, shufLabOH, batch_size=10, n_epoch=50, show_metric=True, validation_set=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
