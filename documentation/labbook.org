#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+OPTIONS: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+OPTIONS: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+TITLE: labbook_heart-cnn
#+DATE: <2018-05-02 Wed>
#+AUTHOR: mike
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.1.1 (Org mode 9.1.7)

* Todo
** DONE Improve old parametric sims
** TODO Get some real identities CAM
** DONE Change to [32,32,32,2] shape
** DONE Sort out mess of CNNs
** DONE Distributed CNN
** TODO Get GAN working
** TODO Large scale CNN testing
** TODO Parallel computing methods SPEED RACE
* Dates
** 2017-07-03 INITIAL SET UP

- Initial set up of neural net, based on leNet-5, no signal out, most
  likely due to using unprocessed data.
- The data is very padded, this has been reduced with the function
  =cropHeart(inp)=, but I will need to make sure all the files are the
  same size before they get fed into the CNN.
- I could try normalising the data to get a signal, but will need to
  get the unpadded data working first.

** 2017-07-04 VISUALISER

-  Wrote a visualisation of the data (=visualisation.py=).
-  Still working on repadding the cropped data (It's a bit of a pain).

** 2017-07-05 DATA CROPPING AND INITIAL SIGNAL

- Repadded the cropped data, it is now of size [68,34,34].
- Retrying the CNN with the new data doesn't get a signal. Maybe there
  isn't enough data to make it work?
- I will fiddle with the hyperparams to see if I can pick something up.
- Maybe normalising the data will help.

*Got some results using 2D slices:* 
- The 2D slices I used look like:
[[../figures/pics/fCalmX.png][2D slice data example]]
- I have used 2d slices of the data and it works well (halfway 
  through the z-axis). It uses: 
  - Slice of rest and slice of stress on z axis.
  - Spacial x and spacial y on x and y axes. 
  - LeNet-5 CNN with 3D convolution and subsampling. 
  - [2,5,5] filters, pooling 2 with step 2. 
  - learning rate of 0.0001, with ADAM optimiser, and batch size of 10. 
  - After 50 epochs of 58 images it learns to ~95%.

- I will now apply a k-fold x-validation to it to see if it's not just
  picking up noise.
- The k=10-fold x-validation shows that the CNN is learning the noise
  in the data, although this could be due to the small amount of images
  in each k-fold (only 6!):
    [[../figures/rocCurves/2017-07-05_14:37:00-2dsliceCNN.png][ROC curve from 2D slice CNN 2017-07-05]]
- I tried normalising the arrays, with no luck. It stopped overfitting
  the data, but still hasn't learnt significantly:
  [[../figures/rocCurves/2017-07-05_15:30:00-2dsliceCNN.png][ROC curve from normalised 2D slice CNN 2017-07-05]]
- I think the issue is still the massive amount of blankspace. I should
  try and scale the arrays so that they are the same size.

*Have a signal!* 
- I have got a signal with the following CNN: 
  - Slice of rest and slice of stress on z axis. Spacial x and spacial y on x and y axes. 
  - LeNet-5 CNN with 3D convolution and subsampling. 
  - [2,10,10] filters, pooling 2 with step 2. 
  - learning rate of 0.0001, with ADAM optimiser, and batch size of 10. 
  - 5 k-folds. 
- After 50 epochs of 47 images it learns training data to ~95%. 
- Over three repeats: 
  - Avg Spec: 0.583, 0.623, 0.663 
  - Avg Sens: 0.633, 0.683, 0.700 
  - ROC curves:
[[..igures/rocCurves/2017-07-05_16:31:00-2dsliceCNN.png][ROC curve from normalised 2D slice CNN 2017-07-05]]
[[../figures/rocCurves/2017-07-06_09:55:00-2dsliceCNN.png][ROC curve from normalised 2D slice CNN 2017-07-06]]
[[../figures/rocCurves/2017-07-06_10:20:00-2dsliceCNN.png][ROC curve from normalised 2D slice CNN 2017-07-06]]

** 2017-07-06 SCALING AND RESIZING

- I redid the 2D slice data with three slices along the x, y, and z
  axes. It will take ~100 mins to finish learning. It's probably time
  to use some better hardware.
- Found a function
  [[https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.zoom.html][]]
  which should work well for resizing the images.
- Maybe the reason that the slicing works, and the 3D data doesn't is
  because the CNN filter only sees one 3D image at a time, and sees
  both the rest and stress images at the same time in the 2D slice
  data. I could write a 4D CNN to fix this.

- mhuen seems to have written a 4D convolution by stacking 3D CNN
  outputs[[https://github.com/mhuen/TFScripts/blob/master/py/tfScripts.py][]].
  This might work for what I want to do, and stacking can be used
  for pooling too.

- I wrote a scaling function hat eliminates most of the whitespace.
- After training the CNN did not learn significantly.
- Added a ROC AUC calculator to the outputs.
- I'm going to try artificially expanding the data.

** 2017-07-07 OVERFITTING PROBLEMS

- Because of the overfitting going on when running the CNN, I increased
  the L2 regularisers' weight decay from 0.001 to 0.01, and added an
  extra dropout layer between the two FC dense layers.
- Can't seem to get any results with a spec/sens over 60%, probably due
  to the way I'm orgainising the data.

- The CNN appears to train better when using non-scaled data. I can't
  figure out why. Maybe it's using the image sizes as an aid?

   - Conv filter: [2,15,15]; pool filter: [2,2,2]; 2 FC 1024 neurons,
     L2 regulisation at weight decay = 0.001, dropout at 0.5 after each
     FC layer; ADAM optimiser, learning rate = 0.0001, categorical
     x-entropy loss; batch size = 10 at 38 datum; k = 3 folds.

      - non-scaled:
        [[../figures/rocCurves/2017-07-07_11:34:00-2dsliceCNN.png][ROC curve from normalised 2D slice CNN 2017-07-05]]
      - scaled:
        [[../figures/rocCurves/2017-07-07_11:50:00-2dsliceCNN.png][ROC curve from normalised 2D slice CNN 2017-07-05]]
      - scaled, not renormalised:
        [[../figures/rocCurves/2017-07-07_13:41:00-2dsliceCNN.png][ROC curve from normalised 2D slice CNN 2017-07-05]]

- As shown in the ROC curves, the only data that is causing consistent
  learning is the non-scaled one. I don't know why.

- Rewrote heart\_data.ipynb so that it can resize the input data.

** 2017-07-10 ARTIFICIAL EXPANSION AND CNN ARCH

- It might be better to use a Siamese CNN instead of a 4D CNN to
  compare two 3D images, as training will be faster.

   - I have written CNNs using two-channel, and Siamese architectures,
     along with the OG 3D convolution architecture. The two-channel and
     Siamese architectures are described here:
     [[https://arxiv.org/pdf/1504.03641.pdf][]].

- The use of a very deep NN architecture would reduce linearity, and
  may be useful.

- Artificially expanding the data seems to have worked. I am getting
  after k = 3 folds (100 epochs) at 619 datum (two runs):

   - Spec: 0.864, 0.917
   - Sens: 0.888, 0.883
   - ROC AUC: 0.918, 0.940
   - This is with the two-channel architecture. ROC curves:

      - [[../figures/rocCurves/2017-07-10_13:16:00-2dsliceCNN.png][ROC curve from expanded data two-channel CNN 2017-07-10]]
      - [[../figures/rocCurves/2017-07-10_13:49:00-2dsliceCNN.png][ROC curve from expanded data two-channel CNN 2017-07-10 second repeat]]

- Haven't got any significant results from the Siamese CNN, but have
  only trained it to ~30 epochs. It will probably need more training
  than the two-channel as there are nearly twice as many weights in the
  Siamese CNN.
- I should try validating the CNN on ppts that it hasn't seen before
  (like take 10 ppts from the pool before artificial expansion and use
  these to validate).

** 2017-07-11 K-FOLDING

- I have separated ppts into different k-folds before expansion, so
  each k-fold has unique ppts in it now, even after artificial
  expansion. We'll see how it performs now... (This is in the 2channel
  ipynb)

   - It doesn't work very well. Getting ~50% accuracy.

      - [[../figures/rocCurves/2017-07-11_14:20:00-2dsliceCNN.png][ROC curve from exp data 2-channel (different ppts in each k-fold) CNN 2017-07-11]]

- More data would be helpful to reduce overfitting, but using all three
  dimensions of the heart data may be enough to get "good enough"
  results.

- I have written a 2 channel CNN for the 3D data. It should be ready to
  try on the supercomputer.

** 2017-07-12 2D CNN

- Testing the 2dSiameseCNN on the supercomputer:
  =$ qsub -q gpu -l nodes=1:ppn=16 -I -X -l walltime=24:00:00= It
  doesn't seem to work. How long is the queue?
- I have found a bug in the 2dsliceCNN that may be causing the lack of
  learning. The expansion doesn't relabel the expanded data correctly.
  I have hopefully fixed this.
- Running for 20 epochs @ k = 5 folds to see how it does.

   - Again, ~50% accuracy.

- I have increased the number of conv layers to 4.

   - No change.

- Running the 3D CNN on the hub. It looks like it takes ~20 epochs to
  train to 100% (I should use validation to see if/when it starts
  overfitting). It also takes ~12s to train an epoch. To contast it
  takes my computer ~16mins per epoch, an 80x speedup.

- Added 4(!) new convolution layers to 3D CNN. Since this reduces
  linearity, we may find something.

   - Getting some odd results. The CNN comes out with the opposite of
     what I was expecting (low ROC, accuracy).
   - Look at labelling, try on simpler data (MNIST 0s and 1s?),
     reintroduce k-folding?

** 2017-07-14 3D CNN

- Added overall average performance metric to 3dCNN-nokfold.
- I think I have found the cause of the low ROC/accuracy. The random
  state shuffle is set to 1. If I change it, it may get some more
  believable results.
- Looks like that was what the issue was. The CNN got lucky with the
  cubes taken out for testing:

   - [[../figures/rocCurves/2017-07-14_10:18:00-3dCNN-nok.png][ROC curve from 2-channel 3D CNN 2017-07-14]]
   - [[../figures/rocCurves/2017-07-14_10:48:00-3dCNN-nok.png][ROC curve from 2-channel 3D CNN 2017-07-14]]

- Using fake data to train a CNN. It's found on =/data/jim/Heart/sims=.
- The CNNs aren't training. For normal/infarction data I have the loss
  decreasing but the accuracy is static.
  [[https://www.reddit.com/r/cs231n/comments/4p12oc/what_does_it_mean_when_the_loss_is_decreasing/][]]
  < It looks like it is due to the CNN training well on "easy"
  examples.

** 2017-07-24 CNN ARCH

- Trying a CNN with both heart cubes encoded as one (through matrix
  multiplication).
- The fake data doesn't seem to be working. I should look for ways to
  reduce noise in it.
- There was an error in my normalisation function. I'm going to go back
  and fix it and see if anything happens.
- It's finding something, but it looks like it's getting stuck in local
  minima. I'll fiddle about with the learning rate.
- Reducing the ppts to 50 healthy 50 unhealthy has got an accuracy of
  ~70%. This is promising. Maybe the CNN just needs a while to learn?
- Got this:

   - [[./figures/rocCurves/2017-07-24_14:43:00-3dCNNfakedata.png][ROC curve with new normalisation routine 2017-07-24]]

- Running again with 400 epochs. Taking ~20 min per k-fold of 100 ppts.
  I should try this with the full dataset. It will take a long time (~7
  hours), so if this works I'll run overnight.
- Got this for 400 epochs:

   - [[./figures/rocCurves/2017-07-24_15:39:00-3dCNNfakedata.png][ROC curve with new normalisation routine (400 epoch) 2017-07-24]]

- Set up a job for overnight. We'll see how it does tomorrow.

** 2017-07-25 RUNNING 3D CNN ON SUPERCOMPUTER

- To run headless on a server I need the following at the top
  (matplotlib uses X by defualt).

  #+BEGIN_SRC python
      import matplotlib
      matplotlib.use('Agg')
  #+END_SRC

- Rerunning the 400 epoch 1500 ppt CNN...
- There may be an issue with the resizing of the arrays into the
  zeroArr. I think removing the centring code fixes it, and doesn't
  affect the CNN. Running a test on the 2D CNN.

   - I can safely remove the centring code.

- It takes a very long time to denoise the heart cubes. Will need to do
  this on the server.
- OOM error! I will need to rewrite the python script so that each
  k-fold is considered separately. Looks promising though: ~0.6
  accuracy after 400 epochs.

** 2017-07-26 RESULTS

- The results from the latest run have training accuracy at 55%, with
  validation accuracy around the same (mean AUC = 0.54). I'll try again
  with less regularisation (it may be underfitting).

   - [[../figures/rocCurves/2017-07-26_12:59:00-3dCNNfakedat500epoch.png][ROC curve from normalised 2D slice CNN 2017-07-05]]

- Rewrote cnn.py so that the logging is more transparent (in plaintext
  after each k-fold).
- Rerunning the CNN with 500 epochs without dropout. Will be done
  tomorrow.
- I took out the resizing movement from cnn.py between the 60% and 55%
  runs. If there is no improvement in the current run I should put it
  back in:

  #+BEGIN_SRC python
      ##### There is probably a better way of doing this...
      if calm3d.shape[0] != 34:
          startInd = (34 - calm3d.shape[0])/2
          zeroArr0[startInd:calm3d.shape[0]+startInd,:calm3d.shape[1],\
              :calm3d.shape[2]] = calm3d
      if calm3d.shape[1] != 34:
          startInd = (34 - calm3d.shape[1])/2
          zeroArr0[:calm3d.shape[0],startInd:calm3d.shape[1]+startInd,\
              :calm3d.shape[2]] = calm3d
      if calm3d.shape[2] != 34:
          startInd = (34 - calm3d.shape[2])/2
          zeroArr0[:calm3d.shape[0],:calm3d.shape[1],\
              startInd:calm3d.shape[2]+startInd] = calm3d


      if stress3d.shape[0] != 34:
          startInd = (34 - stress3d.shape[0])/2
          zeroArr1[startInd:stress3d.shape[0]+startInd,:stress3d.shape[1],\
              :stress3d.shape[2]] = stress3d
      if stress3d.shape[1] != 34:
          startInd = (34 - stress3d.shape[1])/2
          zeroArr1[:stress3d.shape[0],startInd:stress3d.shape[1]+startInd,\
              :stress3d.shape[2]] = stress3d
      if stress3d.shape[2] != 34:
          startInd = (34 - stress3d.shape[2])/2
          zeroArr1[:stress3d.shape[0],:stress3d.shape[1],\
              startInd:stress3d.shape[2]+startInd] = stress3d
  #+END_SRC

- I have updated cnn.py to start saving the trained CNN models.
- It might also be beneficial to start using the real data as a
  validation set.
- Processing the log files would be better done in an ipynb.

** 2017-07-27 RESULTS

- Results from last run have an average specificity of 0.54, and an
  average sensitivity of 0.62. The AUC average is 0.60.

  - [[../figures/rocCurves/2017-07-27_09:45:00-3dCNN2chfakedata.png][ROC curve from less regularised CNN 2017-07-26]]

- This is with

  #+BEGIN_SRC python
      # Neural net (two-channel)

      sess = tf.InteractiveSession()
      tf.reset_default_graph()
      tflearn.initializations.normal()

      # Input layer:
      net = tflearn.layers.core.input_data(shape=[None,34,34,34,2])

      # First layer:
      net = tflearn.layers.conv.conv_3d(net, 32, [10,10,10],  activation="leaky_relu")
      net = tflearn.layers.conv.max_pool_3d(net, [2,2,2], strides=[2,2,2])

      # Second layer:
      net = tflearn.layers.conv.conv_3d(net, 64, [5,5,5],  activation="leaky_relu")
      net = tflearn.layers.conv.max_pool_3d(net, [2,2,2], strides=[2,2,2])

      # Fully connected layers
      net = tflearn.layers.core.fully_connected(net, 2048, regularizer="L2", weight_decay=0.01, activation="leaky_relu")
      #net = tflearn.layers.core.dropout(net, keep_prob=0.5)

      net = tflearn.layers.core.fully_connected(net, 1024, regularizer="L2", weight_decay=0.01, activation="leaky_relu")
      #net = tflearn.layers.core.dropout(net, keep_prob=0.5)

      net = tflearn.layers.core.fully_connected(net, 512, regularizer="L2", weight_decay=0.01, activation="leaky_relu")
      #net = tflearn.layers.core.dropout(net, keep_prob=0.5)

      # Output layer:
      net = tflearn.layers.core.fully_connected(net, 2, activation="softmax")

      net = tflearn.layers.estimator.regression(net, optimizer='adam', learning_rate=0.000001, loss='categorical_crossentropy')
      model = tflearn.DNN(net, tensorboard_verbose=0)

      # Train the model, leaving out the kfold not being used
      dummyData = np.reshape(np.concatenate(kfoldData[:i] + kfoldData[i+1:], axis=0), [-1,34,34,34,2])
      dummyLabels = np.reshape(np.concatenate(kfoldLabelsOH[:i] + kfoldLabelsOH[i+1:], axis=0), [-1, 2])
      model.fit(dummyData, dummyLabels, batch_size=100, n_epoch=500, show_metric=True)
  #+END_SRC

- I am convinced that the CNN is finding something. Will push the new
  cnn.py to github so that we can test the trained nets on real data.
- New CNN further reduces regularisation, and increases learning rate
  from 0.000001 to 0.0001.
- Writing a python script that finds the part(s) of the cube that the
  CNN uses for diagnosis.

  - I will need to test it when I have some models, but it looks like
    it will work. It is saved as =getDiagArea.py=.

- Latest CNN results:

  - AVG spec 0.62, AVG sens 0.61, AVG AUC 0.66. (Over k=3 folds).
  - [[../figures/rocCurves/2017-07-27_18:04:00-3dCNN2chfakedata.png][ROC curve from less regularised CNN 2017-07-26]]

** 2017-07-31 RESULTS

- Newest results are in with the following CNN:

#+BEGIN_SRC python
        # Neural net (two-channel)

        sess = tf.InteractiveSession()
        tf.reset_default_graph()
        tflearn.initializations.normal()

        # Input layer:
        net = tflearn.layers.core.input_data(shape=[None,34,34,34,2])

        # First layer:
        net = tflearn.layers.conv.conv_3d(net, 32, [10,10,10],  activation="leaky_relu")
        net = tflearn.layers.conv.max_pool_3d(net, [2,2,2], strides=[2,2,2])

        # Second layer:
        net = tflearn.layers.conv.conv_3d(net, 64, [5,5,5],  activation="leaky_relu")
        net = tflearn.layers.conv.max_pool_3d(net, [2,2,2], strides=[2,2,2])

        # Third layer:
        net = tflearn.layers.conv.conv_3d(net, 128, [2,2,2], activation="leaky_relu") # This was added for CNN 2017-07-28

        # Fully connected layers
        net = tflearn.layers.core.fully_connected(net, 2048, activation="leaky_relu") # regularizer="L2", weight_decay=0.01,
        #net = tflearn.layers.core.dropout(net, keep_prob=0.5)

        net = tflearn.layers.core.fully_connected(net, 1024, activation="leaky_relu") # regularizer="L2", weight_decay=0.01,
        #net = tflearn.layers.core.dropout(net, keep_prob=0.5)

        net = tflearn.layers.core.fully_connected(net, 512, activation="leaky_relu") # regularizer="L2", weight_decay=0.01,
        #net = tflearn.layers.core.dropout(net, keep_prob=0.5)

        # Output layer:
        net = tflearn.layers.core.fully_connected(net, 2, activation="softmax")

        net = tflearn.layers.estimator.regression(net, optimizer='adam', learning_rate=0.0001, loss='categorical_crossentropy')
        model = tflearn.DNN(net, tensorboard_verbose=0)

        # Train the model, leaving out the kfold not being used
        dummyData = np.reshape(np.concatenate(kfoldData[:i] + kfoldData[i+1:], axis=0), [-1,34,34,34,2])
        dummyLabels = np.reshape(np.concatenate(kfoldLabelsOH[:i] + kfoldLabelsOH[i+1:], axis=0), [-1, 2])
        model.fit(dummyData, dummyLabels, batch_size=100, n_epoch=150, show_metric=True) # In practice learning stops ~150 epochs.
        dt = str(datetime.datetime.now().replace(second=0, microsecond=0).isoformat("_"))
        model.save("./models/"+dt+"_3d-2channel-fakedata_"+str(i)+"-of-"+str(k)+".tflearn")
#+END_SRC

- Avg AUC, spec, sens (over 5 k-folds): 0.762, 0.630, 0.735.

   - [[../figures/rocCurves/2017-07-31_10:29:00-3dCNN2chfakedata.png][ROC curve from less regularised CNN 2017-07-28]]

- Results for the models applied to real data (avg AUC, spec, sens):
  0.544, 0.814, 0.207.

   - [[../figures/rocCurves/2017-07-31_13:26:00-3dCNN2chrealdata.png][ROC curve from application of CNN 2017-07-28 to real data]]
     
** 2017-08-01 CNN ARTEFACT VIS

- The visualisation of where the CNN is diagnosing the patient is
  ready, but it doesn't seem to be looking in the correct places. Maybe
  the two matrices aren't aligned properly?

** 2017-08-02 CNN ARTEFACT VIS

- Adding another conv layer to the CNN doesn't improve things. Moving
  back to previous CNN...
- Wrote a standalone visualisation for the loss cubes.
- I will tinker around with the CNN and see if I can get any more
  performance out of it.
- Added another FC layer to the CNN. We'll see how it does.
- Tried using a larger filter in the getDiagArea.py file. Running now,
  will take a while because the GPU is busy with the new CNN.

   - Looking at the STDOUT it seems like the filter may be too large. I
     should try a smaller one next time (4?).

- The new CNN doesn't seem to have improved on the previous either.
  Maybe I need to change the learning rate or the number of epochs?
- It might be helpful to write a GAN so that we can see what the CNN
  decides a heart cube looks like.
- I have found this: [[https://arxiv.org/pdf/1512.03385v1.pdf][]]. When
  the latest CNN is done training I'll use a very deep cnn to see if we
  can do any better than 70% acc.

** 2017-08-03 RESULTS

- OOM when running prediction on new cnn. It is only getting ~0.63
  accuracy on the validation dataset so no big loss. Reverting to
  previous cnn...
- Looks like the OOM error is due to using 2000 training samples in the
  data.
- The CNN is looking in the "wrong place" to find the problems... I
  don't know why. It is diagnosing the images correctly regardless of
  this.

   - [[../figures/diagnoses/heatmapExample0.png][Heatmap diagnosis 2017-08-03 to real data]]

- I could try using the average of the k-folds to see where the
  diagnostic part is, instead of just one k-fold. I will need to do
  this after vDeepCNN has finished training.

  #+BEGIN_SRC python
      ### vDeepCNN: ###
      # Input layer:
      net = tflearn.layers.core.input_data(shape=[None,34,34,34,2])

      net = tflearn.layers.conv.conv_3d(net, 32, 7, activation="leaky_relu")
      net = tflearn.layers.conv.max_pool_3d(net, 2, strides=2)
      # Keep running into OOM errors with this...
      net = tflearn.layers.conv.conv_3d(net, 32, 3,  activation="leaky_relu")
      net = tflearn.layers.conv.conv_3d(net, 32, 3,  activation="leaky_relu")
      net = tflearn.layers.conv.conv_3d(net, 32, 3,  activation="leaky_relu")

      net = tflearn.layers.conv.conv_3d(net, 32, 3,  activation="leaky_relu")
      net = tflearn.layers.conv.conv_3d(net, 32, 3,  activation="leaky_relu")
      net = tflearn.layers.conv.conv_3d(net, 32, 3,  activation="leaky_relu")
      net = tflearn.layers.conv.max_pool_3d(net, 2, strides=2)

      net = tflearn.layers.conv.conv_3d(net, 64, 3,  activation="leaky_relu")
      net = tflearn.layers.conv.conv_3d(net, 64, 3,  activation="leaky_relu")
      net = tflearn.layers.conv.conv_3d(net, 64, 3,  activation="leaky_relu")

      net = tflearn.layers.conv.avg_pool_3d(net, [9,9,9], padding='valid')

      # Output layer:
      net = tflearn.layers.core.fully_connected(net, 2, activation="softmax")

      net = tflearn.layers.estimator.regression(net, optimizer='adam', learning_rate=0.000001, loss='categorical_crossentropy')
      model = tflearn.DNN(net, tensorboard_verbose=0)

      # Train the model, leaving out the kfold not being used
      dummyData = np.reshape(np.concatenate(kfoldData[:i] + kfoldData[i+1:], axis=0), [-1,34,34,34,2])
      dummyLabels = np.reshape(np.concatenate(kfoldLabelsOH[:i] + kfoldLabelsOH[i+1:], axis=0), [-1, 2])
      model.fit(dummyData, dummyLabels, batch_size=100, n_epoch=600, show_metric=True) # In practice learning stops ??? epochs.
  #+END_SRC

- k-folded getDiagArea is gtg when gpu is free.

** 2017-08-04 vDEEPCNN

- vDeepCNN with average pooling at the end doesn't seem to work. It
  does seem to work with FC layers. I'll set that running before I
  leave.
- Running the getDiagArea k-folding doesn't seem to show anything
  new... Why is the CNN looking at where it is?

   - [[../figures/diagnoses/heatmapExample1.png][Heatmap example of all k-folds patient 20 in inData.npy]]

- It seems like the CNN is looking at the denser bits of the heatmap.
- I could try training the CNN on the simulated data and then
  fine-tuning the CNN on the real data...

** 2017-08-07 HDF5 AND FINETUNING

- Only using the real data doesn't find anything.
- Finetuning model with cnnFinetune.py
- It works well!

   - [[../figures/rocCurves/2017-08-07_14:13:00-finetunedCNNrealdata.png][Finetuned CNN ROC curve]]
   - [[../figures/rocCurves/2017-08-07_14:41:00-finetunedCNNrealdata.png][Finetuned CNN ROC curve]]

- Trying with learning rate = 0.00001, 50 epochs:

   - [[../figures/rocCurves/2017-08-07_15:03:00-finetunedCNNrealdata.png][Finetuned CNN ROC curve]]

- Getting better results with the fake data would probably correspond
  to better results in the finetuned CNN with real data.
- Since we have an unlimited amount of fake data I should find a way to
  get it working without an OOM error.
- I am rewriting the CNN to handle the data via HDF5.

** 2017-08-08 HDF5 and tflearn.predict issues

- HDF5 CNN is up and running. The tflearn.predict class is a bit of a
  pita as it loads all the input data into vram before usage. I have
  reduced the input data to 500 ppts to counteract this but there is
  probably a smarter way to do it (feed\_dicts?).

   - Fixed the issue by running each heartcube through tflearn.predict
     via a for loop. The HDF5 file then only fetches one heartcube at a
     time into ram.

- Running cnnH5.py on the CNN used in 2017-07-28.

** 2017-08-10 FINETUNING

- Running the CNN with 19000 samples gives a validation accuracy of
  ~0.8.
- ROC curve:

   - [[../figures/rocCurves/2017-08-10_10:04:00-CNNh5.png][20000 data]]

- The ROC curve for the real data is ok:

   - [[../figures/rocCurves/2017-08-10_10:35:00-CNNh5-finetunedRealData.png][Finetuned data]]

- There isn't a lot of carryover between the sets. It would be better
  to train the CNN from scratch on real data. It might also be better
  to use some more realistic fake data.

** 2017-08-14 PAIRWISE CNN

- Running the CNN on mixed, infarction, ischaemic, artefact, and
  healthy patients pairwise. Only using 20 epochs of 10000 examples of
  ill/healthy.
- It takes ages putting the hearts into *.h5...

** 2017-08-15 PAIRWISE CNN RESULTS

- Here are the ROC curves for the pairwise data (20 epochs, 10000
  ill/10000 healthy). The ROC curve should begin at
  =[fpr,tpr] == [0,0]= but I forgot to manually add that index.

   - [[../figures/rocCurves/2017-08-15_10:15:00-CNN-pairwise.png][20000 data pairwise CNNs]]

- I am going to run a CNN for categorising 10000 infarcted, ischaemic,
  mixed, artefact, and healthy hearts. I cannot use ROC curves for this
  because it is no longer binary, but I can get the overall accuracy,
  along with some other related ops. I think ~60 epochs will be enough.
  I will use validation to see where learning stops.
- There is a problem with my install of mayavi, and the diagnosisCubes
  won't show any more. Idky...
- cnnAll.py should take ~20 hours.

** 2017-08-16 PAIRWISE CNN RESULTS

- We get a validation and test accuracy of ~0.471, and a training
  accuracy of 0.99. I will turn on some regularisation to stop the
  overfitting.

   - Accuracies for each cube type: Normal 0.583; Ischaemia 0.614;
     Infarction 0.298; Mixed 0.274; Artefact 0.583.

- I'll set the epochs to ~30 so that it doesn't take an age..
- Separating the healthy and categorising all the other cubes as ill
  would allow us to make an ROC cube.

   - Written cnnAll with the new ROC/auc curve algorithm.

- Regularisation atm is way too high. Changed the weighting to 0.0001.

** 2017-08-18 REGULARISATION

- The regularisation of 0.0001 has achieved a ~2% increase in accuracy.
  Although this might be within the margin of error.

** 2017-08-21 BUG FIXING

- There are a load of bugs in the ROC generation in cnnAll.py.
  Fixing...
- I think I have fixed all the bugs now. Running the ROC generator.

** 2017-08-22 RESULTS

- We are getting an AUC score of ~0.81. I will run the cnnAll again and
  see if we can finally get an ROC curve from this.
- Passing each heartcube through tf.predict is not very efficient... If
  this becomes an issue I can try passing slices instead.

** 2017-08-23 CNNALL.PY

- Looks like the supercomputer is having trouble processing the code.
  Splitting the CNN training and ROC/AUC evaluation into separate
  =*.pys=, and linking them with a shell script may help.
- I can probably remove all the cruft and leave the diagnosis cube, and
  =cnnAll.py= since cnnAll implements the 3D CNN to all types of heart,
  and has a solid evaluation output (ROC, acc for each illness, etc.).

** 2017-08-24 SLOWING GPU

- The computer timed out... :(
- I think the GPU is slowing because it is nearly OOM... Maybe split
  the diagnostics and model building?
- I could probably also generate ROC curves for each ill/healthy pair,
  but this would take a long time on the computer we have.

** 2017-08-28 SLOW GPU FIXED

- Fixed the slowing problem. The masking of the inData\_test array was
  performed for each prediction, meaning each masked array was stored
  in memory. Moving the mask outside the for loop fixed this.
- I've changed the weight decay to 0.00001 on all FC layers. This might
  fix the overfitting (and low performance) problem with cnnAll.py.

** 2017-08-29 OVERFITTING ISSUE

- The overfitting is still a problem... I have removed one of the FC
  layers, and upped the regularisation on the remaining layers.
- Latest results Normal: [ 0.452] Ischaemic: [ 0.50599999] Infarcted: [
  0.37099999] Mixed: [ 0.47299998] Artefact: [ 0.51699997] Overall
  accuracy: [ 0.46379998] ROC AUC: [ 0.826947]

   - [[../figures/rocCurves/2017-08-31_09:46:00-CNN-all.png][ROC for ill/healthy matchings]]

** 2018-05-02 SIM GEN CHANGES, FINETINED RESULTS

- I have changed the sim generation software so that it looks more like
  the real data.
- Generated 10,000 healthies and 10,000 infarctions (in
  infarction-healthy.h5 and infarction-healthy-test.h5).
- Testing cnnH5.py on healthy/infarction sims: Specificity: 0.835
  Sensitivity: 0.859 ROC AUC: 0.923
  [[../figures/rocCurves/2018-05-02_21:12:00-roc_curve.png][ROC infarction/healthy sims]]
- Wrote a new postproc so that we can easily get the ROC AUC, and other
  values out.
- Rerunning on latest CNN...
- Will finetune with real scans when done.
- Finetuned results: @150 epochs: Specificity: 0.363 Sensitivity: 0.755
  ROC AUC: 0.651
  [[../figures/rocCurves/2018-05-02_21:40:00-roc_curve.png][ROC at 150 epochs finetuned]]

  @20 epochs: Specificity: 0.280 Sensitivity: 0.777 ROC AUC: 0.646
  [[../figures/rocCurves/2018-05-02_21:48:00-roc_curve.png][ROC at 20 epochs finetuned]]

- This is exciting! We are finding transferability between real and
  simulated scan diagnosing. We just need to improve the sims with a 3D
  GAN. 

** 2018-05-04 POLAR PLOT VIS
- Polar plot is tentatively up:
  [[../figures/diagnoses/polar_plot.png][polar plot example]]
- Not *great* and I think we can do much better, but for now, we know it works.
- Writing up a python visualisation module now.

** 2018-05-07 BRUTE FORCE PLOT VIS
- visualise.py is working for cartesian and polar coord systems. 
  I need to figure out a way to get the diagnosis cube into it for the folded visualisation.
  This should be easy enough...
- Losscube needs a BIG rework... it barely works at all. Now that we have working 2d visualisations, we should
  try and get the losscube up and running again with the new vis-es.
- We are getting something... Will play around with it more tomorrow.
[[../figures/visualisations/1525726948.409029-cartesian.png][Visualisation of losscube.]]

** 2018-05-08 ARTEFACT SITE VIS
- Losscube overlay for visualisation is working well now:
[[../figures/visualisations/1525810383-polar.png]]
[[../figures/visualisations/1525810383-cartesian.png]]
[[../figures/visualisations/1525810383-unfolded.png]]
- There appears to be a bug in the lossCube code, or the CNN is not looking at all where we expected it too...
[[../figures/visualisations/1525810428-polar.png]]
[[../figures/visualisations/1525810428-cartesian.png]]
[[../figures/visualisations/1525810428-unfolded.png]]
- I will try and fix this tomorrow.

** 2018-05-09 GRAD CAM
- I'm going to implement a grad cam to go along with the already implemented occlusion mapping. 
  If they are "looking" in the same area, we can conclude that the CNN is where the "bug" is.
 
** 2018-05-10 *JUST* CAM
- Still implementing grad cam, having trouble with getting the gradients from tflearn... Should probably switch to Keras.
- A simple class activation map might work! Since the tflearn CNN is simple, rewriting it wouldn't be too much trouble: putting
  a 3D global average pool in the final layer would create a CNN that will natively generate a CAM! Who liked FC layers anyway?

** 2018-05-11 FULLY-CNN
- Written the new CNN:
  - Three convolutional layers interspersed with max pooling layers.
  - A fourth convolutional layer followed by a global average pool (tf.reduce_mean(x, [1,2,3]).
- It seems to be training pretty well. Will see how it does on the test data.
- To get class activation maps:
  - Get output of final conv layer, A_i.
  - Get weights of each layer from the global average pool, w_i.
  - CAM = sum(A_i*w_i)
- CNN is now written to allow observation.

*** Results from new fully-CNN (fakeData):
- Spec 0.779, Sens 0.924, AUC, 0.915
[[../figures/rocCurves/2018-05-11_18:05:00-roc_curve.png]]

- Occlusion map and CAM are looking in different places... very odd.
- CAM is not being resized at the moment!
- Looks like CAM is looking at the top right corner....
  
** 2018-05-14 CAM AND OCCLUSION MAP PROBLEM
- We have a problem with both the CAM and the occlusion map.
  - Both look in the wrong place, and in different wrong places.
- Going to see if I can debug on the MNIST dataset.
  - There may be an issue with the observer in CNNs/CNN.py:
    *defining two tflearn.DNN() consecutively messes with the loss.*
- We still get the same error with the MNIST and the CAM mapping. There must be a bug
  in the code that I am missing...
- Occlusion mapping works well.. And a map of 1 works best. I should try this on the real data.
[[../figures/visualisations/occlusion_map.png]]
- It works on the real data!! (I think).
- Testing the CAM on MNIST...
  
** 2018-05-15 CAM IS FASTER THAT O-MAP
- Taking out max pooling in CNN... They aren't needed!! Can be replaced with a larger stridelength in the conv layers.
- Replaced leaky_relu with relu.
- CAM seems to be working on MNIST, but not overly well.. will see if I need any tweaks.
- There is a definite tradeoff between training time and accuracy of CAM output.
    - Less dropout works better for CAM, but worse for computation time.
- MNIST with no pooling:
[[../figures/mnist/realCube.png]]
[[../figures/mnist/lossCube.png]]
[[../figures/mnist/realCube_1.png]]
[[../figures/mnist/lossCube_1.png]]
- MNIST with a final convolution_transpose layer:
[[../figures/mnist/realCube_2.png]]
[[../figures/mnist/lossCube_2.png]]
[[../figures/mnist/realCube_3.png]]
[[../figures/mnist/lossCube_3.png]]
- Looks like it works with a padding of 1 at start of x and y axes:
[[../figures/mnist/without_padding.png]]
[[../figures/mnist/with_padding.png]]
- I will set up the CNN for training now and test this on the sims tomorrow.
- To conclude:
  - Occlusion map works
  - CAM works with resizing.
  - Also CAM is waay faster than occlusion mapping.
    
** 2018-05-16 CAM WORKING, SMALLER KERNEL SIZES
- We have CAM working on heartcube:
[[../figures/visualisations/1526496554-cartesian.png]]
[[../figures/visualisations/1526496554-polar.png]]
- CNN has been changed so that the kernel size is smaller (better localisation).

** 2018-05-17 GAN FOR FAKEDATA
- CNN is not converting to real data (spec = 1.0, sens = 0.0). We need to get better fake data.
- Working on a GAN to generate better data.
- GAN is written for MNIST... testing at 10 epochs.
- Need waay more than that, output from not_my_gan_mnist.ipynb at 100 epochs (full MNIST dataset):
[[../figures/mnist/gan/gan_mnist.png]]
- Using only 50 images/class at 10,000 epochs:
[[../figures/mnist/gan/mnist_restricted_gan.png]]
- Not as bad as I thought.. Trying the GAN is probably worth it then!

** 2018-05-18 WHICH GAN ARCH?
- Stack-GAN looks like a good bet! V1 or V2??
(https://github.com/hanzhanggit/StackGAN-v2, https://github.com/hanzhanggit/stackgan)
- We can leverage its architecture to generate 3D images.
- Also, if we use a conditional GAN we can ask it to generate a bunch of single cubes 
  (like healthy stress for example). This will reduce the work the GAN has to do.
- A problem that might come up is the lack of training data... I don't really see a good way
  around this. We could artificially expand the dataset, but real data would always be better!
- Another problem is the (very large) amount of voxels in our cubes. We have 34^3=39,304 voxels 
  in a heartcube, compared to the stackGAN's 256^2=35,536.
- I have forked Stack-GAN-v2... will try porting over to tensorflow (tflearn).
  
** 2018-05-22 GAN ISSUES
- Having trouble with getting GAN to learn. No change in loss over time.
- output:
[[../gan/figures/2018-05-22-mnist.png]]
- With batch normalisation no change in GAN after 28 epochs.
- Will take a closer look at Stack-GAN and see where I am going wrong.
[[../gan/figures/2018-05-22-mnist_2.png]]  
- Maybe something is happening (see above). 
- After 130 epochs no change..
- Is a complicated GAN needed? A simple FC-NN may be good enough...
  
** 2018-05-23 TRYING ON ECG
- Falling back to ECG GAN generation. It's more interesting than MNIST. Using PTB diagnostic database.
- Generating h5py file of ECG scans.
- h5py file is generated. Will work on GAN tomorrow.
- ecg-gan is in /home/mike/Documents/hertsDegree/ecg-gan
  
** 2018-05-24 USING BEGAN
- Using real data fully CNN with L2 regularization on each layer gives:

|            | Accuracy (1527177683) |
|------------+-----------------------|
| Train      |                0.9687 |
| Validation |                0.9896 |
| Test       |                0.7658 |

- This is a good starting point. The model used here is "1527177683" @ 30 epochs.
- Our GAN has mode collapse. :(
- Using [[https://arxiv.org/pdf/1703.10717.pdf][BEGAN]] as the base GAN. Once this is set up we can "tile" it to get a stacked GAN for
  our SPECT scans.
 
** 2018-05-25 "
- BEGAN is going well. Still some debugging to do. Should get it up and running in a couple of days
  for the ECG dataset.
** 2018-05-28 BEGAN IS FORKED AND RUNNING
- BEGAN is forked and up and running for ECG scans. 
- Training on ill ECGs now. 
- Will wait until solved (at around 19:30 with a five hour training time).
- Doesn't look all too great at 30 epochs. Will leave on for 300.
  
** 2018-05-29 BEGAN NOT WORKING
- BEGAN trained to 300 epochs:
[[../gan/figures/300_epochs.png]]
- Doesn't seem to be converging onto a value...
  - Tried lam=0.0001, lam=0.1, lam=0.001, no convergence.
- Problem with input data??
- Will try and get the ECG to work on the very simple tflearn GAN.
- Sigmoid neurons do not result in good output (seems to be very dichotomous).

** 2018-05-30 PRELIM GAN GEN
- Mnist-gan (for ecg of shape 800) is working with default losses, but we are getting a load 
  of numerical instability (log(x) -> inf as x -> 0).
- tf.maximum(x, 1e-9) is a decent plaster to mitigate this, but there may be a better way...
- Result for ecg of shape 800 at 140 epochs:
[[../figures/ecg-gan/gan-mnist-ecg-example.png]]
- No such luck with a direct translation into the CNN (0.4 accuracy). Maybe a better GAN is needed.
- We can get some decent Cosine similarities (~0.63)!
*** Results
    - Using simulated data results in an improvement(!) over real data:
|                | Sim (1527712130) | Real (1527713245) |
|----------------+------------------+-------------------|
| Acc (train)    |           0.9992 |            0.8999 |
| Acc (validate) |           0.9990 |            0.9089 |
| Acc (test)     |           0.7990 |            0.7284 |

     - This is for the same amount of sims and reals at 5 epochs.

** 2018-05-31 RESULTS
Model 1527177683 (real data) has

    |            | Accuracy |
    |------------+----------|
    | Train      |   0.9687 |
    | Validation |   0.9896 |
    | Test       |   0.7658 |
    
Model 1527712130 (Simulated data with GAN) has (at 5 epochs), compared to model 1527713245 (real, 5 epochs)

    |                |    Sim |   Real |
    |----------------+--------+--------|
    | Acc (train)    | 0.9992 | 0.8999 |
    | Acc (validate) | 0.9990 | 0.9089 |
    | Acc (test)     | 0.7990 | 0.7284 |

** 2018-06-01 DAGAN, BEGAN DEBUG
- Incorporate DAGAN??
  - Will get BEGAN working first
- Removed Sigmoid final layer on GEN (why is it there?)
  - Sigmoid final layer was not the issue.

** 2018-06-05 MORE BEGAN DEBUG
- Is the problem my 1D NN implementation? No.
- Is the problem the use of Fortran reshaping order? No.
- Is the problem gamma? Don't know yet.
- Trying MNIST to see if that offers any insights.
- I should check to see if I'm feeding in the images ok.
- I also need to force diversity in the output (laarge gamma??).

** 2018-06-06 IT WASN'T MY BUG!!
- Training MNIST for 130 epochs does not work.
- Running BEGAN on original data (celebA, B) for 20 epochs to see if it works.
- The problem may be in my 1D conv layers so testing on that.

** 2018-06-07 "
- Artcg's GAN doesn't work on default settings!

** 2018-06-11 "
- Wrong var-scope was being used to update GAN settings!
- Running on supercomputer... Getting no real output. Output looks bad after 300 epochs.
- Own VAE works, but only if I use a absolute difference as a loss.

** 2018-06-14 "
- Need a way to measure variability of the data.
- Once this is done I can measure similarity to OG data too.

** 2018-06-22 AUGMENTING HEART DATA
*** Proposed:
    - Augment via classical augs.
    - Feed augs into GAN
    - Refeed GAN outputs into CNN.

*** Classical AUG:
    - Blur
    - Flip
    - Rotate
    - Translate

- Need to make sure the k-folds don't cross contaminate!!

** 2018-06-25 AUGMENTOR
- AUGMENTOR is running!
- Results of augmented CNN:

   [[../figures/rocCurves/2018-06-27_14:24:00-roc_curve.png]]

- Would bootstrapping result in a better value?
- Look at monte-carlo x-validation, bootstrapping
- Still need to clean the CNN, and make another commit.

** 2018-06-28 AUGMENTOR PT II
- augmentor is redone so that we get an output [58,1024,32,32,32,2]. 
    This keeps the augmented data in bins of similarity.
- Will think of a nice way to mix the data (+kfolds).

** 2018-07-02 BETTER WAY TO KFOLD
- Better way to kfold is a-go. We k-fold by using fancy indexing on both the original data, and the augmented data at the same time.
  - This may be an issue if the augmented data gets much larger but for now, on Ramius, we are doing okay (~30GB RAM needed).
- It may be a good idea to use many seeds for testing (~50?). This would give a more representative result.
- If I get parallel TF working this could be done fairly quickly.

** 2018-07-03 HOROVOD SPEEDUP ON MNIST
- Open-MPI looks like a good parallelisation method but I cannot get this working on gpu1.
- If I do get it working, Horovod looks like a good shout.
- HOROVOD IS UP AND RUNNING!!! -- I will adapt my cnn for horovod
  - It was an installation error on my part (NCCL 2 was not installed, and cuda aware openmpi was installed after horovod!)
    Full installation instructions are in my notebook.

*** Horovod results for MNIST example

    | No GPUS | Global step/sec | Scaling efficiency | Total time | Scaling efficiency |
    |---------+-----------------+--------------------+------------+--------------------|
    |       1 |              90 |                  1 |        238 |                  1 |
    |       2 |             140 |               0.78 |        155 |               0.76 |
    |       3 |             210 |               0.78 |        113 |               0.70 |
    |       4 |             280 |               0.78 |         90 |               0.66 |
    |       5 |             300 |               0.67 |         85 |               0.56 |
    |       6 |             360 |               0.67 |         76 |               0.52 |

** 2018-07-05 OPTIONS FOR PARALLELISATION
- Convert to HVD.
  - PROS: No need to optimise memory usage, entirely in python, very scalable.
  - CONS: Slower than other options for small number of GPUs.
- Run each k-fold/multiple seeds in parallel.
  - PROS: Faster for small number of GPUs. Easy to implement.
  - CONS: Not so scalable, need BASH to set up CUDA_VISIBLE_DEVICES, 
          need to fix data loading issue so that only the current batch is loaded.

** 2018-07-09 HVD AND MOVE TO KERAS
- CNN codebase is moved to Keras, since it is MUCH better than tflearn!
- HVD is now running on Keras backend, and is pushed to testing.
  
** 2018-07-10 FANCY INDEXING FOR BATCH GENERATION
- A Keras generator class has been written to sequentially load our h5 file augmented 
  data into memory batch by batch.

** 2018-07-11 CAM IN KERAS
- CAM has been implemented in Keras.

** 2018-07-12 DISTRIBUTED DISTRIBUTIONS
- We have parallel k-folding AND hvd running now!
- Will need to test their relative speeds.
